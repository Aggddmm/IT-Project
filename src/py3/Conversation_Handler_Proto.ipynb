{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal imports\n",
    "from LM import LMBackend\n",
    "from TTS import TTSBackend\n",
    "from SpeechRecognition import SpeechRecognitionBackend\n",
    "from QuestionClassifier import QuestionClassifierBackend\n",
    "from database_mgr import DatabaseQABackend\n",
    "from AnswerClassifier import Answer_Classifier\n",
    "\n",
    "# external imports\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "# Constants\n",
    "RECORD_THRESHOLD = 200\n",
    "SAMPLING_RATE = 16000\n",
    "REC_DURATION = 1\n",
    "GEMMA_PATH:str = \"/home/aggddmm/Desktop/ITPJ_Aux/gemma-2-2b-it\"\n",
    "WHISPER_PATH:str = \"/home/aggddmm/Desktop/ITPJ_Aux/whisper-small.en\"\n",
    "DB_PATH:str = \"Database/HistoricalQA_DB.sqlite3\"\n",
    "\n",
    "# Switches\n",
    "robot_enable:bool = False\n",
    "# if set to False, use robotSay()\n",
    "USE_DEFAULT_TTS:bool = True\n",
    "ENABLE_POSTURE:bool = False\n",
    "\n",
    "IP_TITLE = \"ip\"\n",
    "PORT_TITLE = \"port\"\n",
    "MESSAGE_TITLE = \"message\"\n",
    "ERROR_TITLE = \"error\"\n",
    "DURATION_TITLE = \"time\"\n",
    "GET = \"GET\"\n",
    "POST = \"POST\"\n",
    "ERROR = -1\n",
    "\n",
    "PY2_SERVER_IP = \"127.0.0.1\"\n",
    "PY2_SERVER_PORT = 26386\n",
    "\n",
    "ROBOT_IP = \"127.0.0.1\"\n",
    "ROBOT_PORT = 9559"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start All Backend Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Database\n",
    "db = DatabaseQABackend(DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Language Model Backend\n",
    "lm_instance = LMBackend()\n",
    "lm_instance.init(GEMMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Speech Recognition Backend\n",
    "sr_instance = SpeechRecognitionBackend()\n",
    "sr_instance.init(WHISPER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Question Classifier Backend\n",
    "qc_instance = QuestionClassifierBackend()\n",
    "qc_instance.init(\"q_classification_model\")\n",
    "# Load Answer Classifier Backend\n",
    "ac_instance = Answer_Classifier()\n",
    "ac_instance.init(\"a_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block to instantiate Python 3 Server\n",
    "def connect_server(ip, port, method, api_entry='/checkConnection', data=None):\n",
    "    if method == GET:\n",
    "        try:\n",
    "            respond = requests.get(\"http://\" + ip + \":\" + str(port) + api_entry)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print (\"[-] Error: \", e)\n",
    "            return ERROR\n",
    "    if method == POST:\n",
    "        try:\n",
    "            respond = requests.post(\"http://\" + ip + \":\" + str(port) + api_entry, json=data)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print( \"[-] Error: \", e)\n",
    "            return ERROR\n",
    "    if respond.status_code != 200:\n",
    "        print (\"[-] Error: \", respond.status_code)\n",
    "        return ERROR\n",
    "    return respond\n",
    "\n",
    "# Connection to Py2 Server\n",
    "if (connect_server(PY2_SERVER_IP, PY2_SERVER_PORT, GET).status_code == 200):\n",
    "    print (\"[+] Py2 - Py3 Server Connection Established\")\n",
    "    # Set Robot IP and Port\n",
    "    \n",
    "    robot_connection_data:dict = {IP_TITLE:ROBOT_IP, PORT_TITLE:ROBOT_PORT}\n",
    "    robot_ip_port = connect_server(ip=PY2_SERVER_IP, port=PY2_SERVER_PORT, method=POST, api_entry='/setRobotIPPort', data=robot_connection_data).json()\n",
    "    \n",
    "    robot_enable = True\n",
    "else:\n",
    "    print (\"[-] Failed to connect to Py2 Server, frezzing robot related functions...\")\n",
    "    robot_enable = False\n",
    "\n",
    "# List all postures, more like a connection test   \n",
    "if (robot_enable):\n",
    "    avail_posture:list = connect_server(ip=PY2_SERVER_IP, port=PY2_SERVER_PORT, method=GET, api_entry='/getAllAvailBehavior').json()[MESSAGE_TITLE]\n",
    "    print (\"[+] Available Postures: \")   \n",
    "    for posture in avail_posture:\n",
    "        print (\"    --> \" + posture)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines posture name\n",
    "thinking_posture:str = \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TTS Backend\n",
    "tts_instance = None\n",
    "if (robot_enable and (not USE_DEFAULT_TTS)):\n",
    "    tts_instance = None\n",
    "else:\n",
    "    tts_instance = TTSBackend()\n",
    "    tts_instance.init(\"espnet/fastspeech2_conformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_instance.classify(\"What is the capital of Italy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Functions of Chatting Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "\"\"\" These functions are from Speech-Recognition branch, with process_audio_stream modified to utlise all backends to generate voice response \"\"\"\n",
    "\"\"\" Different ways to coordinate these functions. \"\"\"\n",
    "\n",
    "def audio_callback(indata):\n",
    "    audio_queue.put(indata.copy())  # Put the captured audio\n",
    "\n",
    "def get_mic_amplitude(input_stream, duration):\n",
    "    data, overflowed = input_stream.read(SAMPLING_RATE * duration)\n",
    "    return np.linalg.norm(data) * 10\n",
    "\n",
    "def process_audio_stream(audio_input:dict) -> None:\n",
    "    \"\"\" from voice input to voice response \"\"\"\n",
    "    if(robot_enable and ENABLE_POSTURE):\n",
    "        connect_server(ip=PY2_SERVER_IP, port=PY2_SERVER_PORT, method=POST, api_entry='/startBehavior', data={MESSAGE_TITLE:thinking_posture})\n",
    "    # recognize audio\n",
    "    sr_result = sr_instance.recognize(audio_input)[\"text\"]\n",
    "    print(\"**** Debug ****: \", sr_result)\n",
    "    # classify question\n",
    "    question_type = qc_instance.classify(sr_result)\n",
    "    print(\"**** Debug ****: \", question_type)\n",
    "    \n",
    "    # Historical Question Pipeline\n",
    "    extra_prompt:str = \"\"\n",
    "    if question_type == \"historicalQuestion\":\n",
    "        db_result = db.get_answer(sr_result)\n",
    "        extra_prompt = \"This question is a historical question. Here is the answer fetched from the database: \\n\"\n",
    "        print(\"**** DB Fetched ****\")\n",
    "        index:int = 1\n",
    "        for row in db_result:\n",
    "            print(\"    \" + str(index) + '. ' + row)\n",
    "            extra_prompt += row + \"\\n\"\n",
    "        extra_prompt += \"If answers above are not relevant, **clearly** state answer not found in database.\\n\"\n",
    "        extra_prompt += \"\\n\"\n",
    "        print(\"**** Debug ****\")\n",
    "    \n",
    "    # generate response\n",
    "    lm_result = lm_instance.generate_text(extra_prompt + sr_result)\n",
    "    \n",
    "    # End Posture\n",
    "    if(robot_enable and ENABLE_POSTURE):\n",
    "        connect_server(ip=PY2_SERVER_IP, port=PY2_SERVER_PORT, method=POST, api_entry='/stopBehavior', data={MESSAGE_TITLE:thinking_posture})\n",
    "        \n",
    "    # generate voice response\n",
    "    if tts_instance is not None:\n",
    "        tts_result = tts_instance.synthesize(lm_result)\n",
    "        # play audio\n",
    "        sd.play(tts_result[\"array\"], samplerate=tts_result[\"sampling_rate\"])\n",
    "        sd.wait()\n",
    "    else:\n",
    "        connect_server(ip=PY2_SERVER_IP, port=PY2_SERVER_PORT, method=POST, api_entry='/robotSay', data={\"message\":lm_result})\n",
    "\n",
    "def debug_player(audio_data):\n",
    "    \"\"\"Debug function to play the audio from the queue.\"\"\"\n",
    "    print(\"Playing audio...\")\n",
    "    sd.play(audio_data, SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dedicated Debug Block For main function\n",
    "cuz bugs really easy to 'be produced' in this block...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" This function controls when to record and when to stop recording \"\"\"\n",
    "    voice_input_stream = sd.InputStream(channels=1, samplerate=SAMPLING_RATE)\n",
    "    voice_input_stream.start()\n",
    "    \n",
    "    sound_amp_queue = queue.Queue()\n",
    "    can_record:bool = False\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # detect sound amplitude to determine if we should record\n",
    "            if (sound_amp_queue.qsize() > 15):\n",
    "                sound_amp_queue.get()\n",
    "            \n",
    "            data, overflowed = voice_input_stream.read(SAMPLING_RATE * REC_DURATION)\n",
    "            volume_norm = np.linalg.norm(data) * 10\n",
    "            \n",
    "            if sound_amp_queue.qsize() < 3:\n",
    "                sound_amp_queue.put(volume_norm)\n",
    "                continue\n",
    "            \n",
    "            # print(\"amplitude queue: \", sound_amp_queue.queue)\n",
    "            avg_mic_amplitude = sum(sound_amp_queue.queue) / sound_amp_queue.qsize()\n",
    "            # only collect background noise level, not outliers.\n",
    "            if abs(volume_norm - avg_mic_amplitude) > RECORD_THRESHOLD:\n",
    "                can_record = True\n",
    "            else:\n",
    "                sound_amp_queue.put(volume_norm)\n",
    "            \n",
    "            if can_record:\n",
    "                print(\"[+] Recording...\")\n",
    "                audio_array = np.empty((0, 1)) \n",
    "                record_amp_queue = queue.Queue()\n",
    "                while can_record:\n",
    "                    audio_array = np.append(audio_array, data)\n",
    "                    data, overflowed = voice_input_stream.read(SAMPLING_RATE * REC_DURATION)\n",
    "                    rec_volume_norm = np.linalg.norm(data) * 10\n",
    "                    # determine when to stop recording\n",
    "                    record_amp_queue.put(rec_volume_norm)\n",
    "                    if record_amp_queue.qsize() > 3:\n",
    "                        record_amp = sum(record_amp_queue.queue) / record_amp_queue.qsize()\n",
    "                        # terminate recording if the amplitude back to normal\n",
    "                        if abs(avg_mic_amplitude - record_amp) < RECORD_THRESHOLD:\n",
    "                            can_record = False\n",
    "                            audio_data = {\"array\": audio_array, \"sampling_rate\": SAMPLING_RATE}\n",
    "                            # process audio stream\n",
    "                            # debug_player(audio_data[\"array\"])\n",
    "                            process_audio_stream(audio_data.copy())\n",
    "                            print(\"Recording stopped.\")\n",
    "                            break\n",
    "                        record_amp_queue.get()\n",
    "    finally:\n",
    "        voice_input_stream.stop()\n",
    "        voice_input_stream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start it UP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPS-Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
