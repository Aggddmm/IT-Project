{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal imports\n",
    "from LM import LMBackend\n",
    "from TTS import TTSBackend\n",
    "from SpeechRecognition import SpeechRecognitionBackend\n",
    "from QuestionClassifier import QuestionClassifierBackend\n",
    "from database_mgr import DatabaseQABackend\n",
    "\n",
    "# external imports\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "audio_queue = queue.Queue()\n",
    "# Constants\n",
    "RECORD_THRESHOLD = 200\n",
    "SAMPLING_RATE = 16000\n",
    "REC_DURATION = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start All Backend Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Database\n",
    "db = DatabaseQABackend(\"Database/HistoricalQA_DB.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] initializing LMBackend\n",
      "    -> Using device:  mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217431c746c44d93b7f0303686f959a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> LMBackend loaded\n"
     ]
    }
   ],
   "source": [
    "# Load Language Model Backend\n",
    "lm_instance = LMBackend()\n",
    "lm_instance.init(\"/Users/lipeihong/Desktop/IT Project/py3/Language_Model/LM/gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] initializing TTS System\n",
      "    -> Using device:  mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FastSpeech2ConformerHifiGan were not initialized from the model checkpoint at espnet/fastspeech2_conformer_hifigan and are newly initialized: ['mean', 'scale']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> TTS System loaded\n"
     ]
    }
   ],
   "source": [
    "# Load TTS Backend\n",
    "tts_instance = TTSBackend()\n",
    "tts_instance.init(\"espnet/fastspeech2_conformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] initializing SpeechRecognitionBackend\n",
      "    -> Using device:  mps\n",
      "    -> SpeechRecognitionBackend loaded\n"
     ]
    }
   ],
   "source": [
    "# Load Speech Recognition Backend\n",
    "sr_instance = SpeechRecognitionBackend()\n",
    "sr_instance.init(\"/Users/lipeihong/Downloads/whisper-small.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'otherQuestion'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Question Classifier Backend\n",
    "qc_instance = QuestionClassifierBackend()\n",
    "qc_instance.init(\"q_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block to instantiate Python 3 Server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Functions of Chatting Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "\"\"\" These functions are from Speech-Recognition branch, with process_audio_stream modified to utlise all backends to generate voice response \"\"\"\n",
    "\"\"\" Different ways to coordinate these functions. \"\"\"\n",
    "\n",
    "def audio_callback(indata):\n",
    "    audio_queue.put(indata.copy())  # Put the captured audio\n",
    "\n",
    "def get_mic_amplitude(input_stream, duration):\n",
    "    data, overflowed = input_stream.read(SAMPLING_RATE * duration)\n",
    "    return np.linalg.norm(data) * 10\n",
    "\n",
    "def process_audio_stream(audio_input:dict) -> None:\n",
    "    \"\"\" from voice input to voice response \"\"\"\n",
    "    # recognize audio\n",
    "    sr_result = sr_instance.recognize(audio_input)[\"text\"]\n",
    "    print(\"**** Debug ****: \", sr_result)\n",
    "    # classify question\n",
    "    question_type = qc_instance.classify(sr_result)\n",
    "    print(\"**** Debug ****: \", question_type)\n",
    "    \n",
    "    extra_prompt:str = \"\"\n",
    "    \n",
    "    if question_type == \"historicalQuestion\":\n",
    "        db_result = db.get_answer(sr_result)\n",
    "        extra_prompt = \"This question is a historical question. Here is the answer fetched from the database: \\n\"\n",
    "        print(\"**** DB Fetched ****\")\n",
    "        index:int = 1\n",
    "        for row in db_result:\n",
    "            print(\"    \" + str(index) + '. ' + row)\n",
    "            extra_prompt += row + \"\\n\"\n",
    "        extra_prompt += \"If answers above are not relevant, **clearly** state answer not found.\\n\"\n",
    "        extra_prompt += \"\\n\\n\"\n",
    "        print(\"**** Debug ****\")\n",
    "    \n",
    "    # generate response\n",
    "    lm_result = lm_instance.generate_text(extra_prompt + sr_result)\n",
    "    \n",
    "    # generate voice response\n",
    "    tts_result = tts_instance.synthesize(lm_result)\n",
    "    \n",
    "    # play audio\n",
    "    sd.play(tts_result[\"array\"], samplerate=tts_result[\"sampling_rate\"])\n",
    "    sd.wait()\n",
    "\n",
    "def debug_player(audio_data):\n",
    "    \"\"\"Debug function to play the audio from the queue.\"\"\"\n",
    "    print(\"Playing audio...\")\n",
    "    sd.play(audio_data, SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dedicated Debug Block For main function\n",
    "cuz bugs really easy to 'be produced' in this block...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" This function controls when to record and when to stop recording \"\"\"\n",
    "    voice_input_stream = sd.InputStream(channels=1, samplerate=SAMPLING_RATE)\n",
    "    voice_input_stream.start()\n",
    "    \n",
    "    sound_amp_queue = queue.Queue()\n",
    "    can_record:bool = False\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # detect sound amplitude to determine if we should record\n",
    "            if (sound_amp_queue.qsize() > 15):\n",
    "                sound_amp_queue.get()\n",
    "            \n",
    "            data, overflowed = voice_input_stream.read(SAMPLING_RATE * REC_DURATION)\n",
    "            volume_norm = np.linalg.norm(data) * 10\n",
    "            \n",
    "            if sound_amp_queue.qsize() < 3:\n",
    "                sound_amp_queue.put(volume_norm)\n",
    "                continue\n",
    "            \n",
    "            # print(\"amplitude queue: \", sound_amp_queue.queue)\n",
    "            avg_mic_amplitude = sum(sound_amp_queue.queue) / sound_amp_queue.qsize()\n",
    "            # only collect background noise level, not outliers.\n",
    "            if abs(volume_norm - avg_mic_amplitude) > RECORD_THRESHOLD:\n",
    "                can_record = True\n",
    "            else:\n",
    "                sound_amp_queue.put(volume_norm)\n",
    "            \n",
    "            if can_record:\n",
    "                print(\"[+] Recording...\")\n",
    "                audio_array = np.empty((0, 1)) \n",
    "                record_amp_queue = queue.Queue()\n",
    "                while can_record:\n",
    "                    audio_array = np.append(audio_array, data)\n",
    "                    data, overflowed = voice_input_stream.read(SAMPLING_RATE * REC_DURATION)\n",
    "                    rec_volume_norm = np.linalg.norm(data) * 10\n",
    "                    # determine when to stop recording\n",
    "                    record_amp_queue.put(rec_volume_norm)\n",
    "                    if record_amp_queue.qsize() > 3:\n",
    "                        record_amp = sum(record_amp_queue.queue) / record_amp_queue.qsize()\n",
    "                        # terminate recording if the amplitude back to normal\n",
    "                        if abs(avg_mic_amplitude - record_amp) < RECORD_THRESHOLD:\n",
    "                            can_record = False\n",
    "                            audio_data = {\"array\": audio_array, \"sampling_rate\": SAMPLING_RATE}\n",
    "                            # process audio stream\n",
    "                            # debug_player(audio_data[\"array\"])\n",
    "                            process_audio_stream(audio_data.copy())\n",
    "                            print(\"Recording stopped.\")\n",
    "                            break\n",
    "                        record_amp_queue.get()\n",
    "    finally:\n",
    "        voice_input_stream.stop()\n",
    "        voice_input_stream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start it UP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Recording...\n",
      "**** Debug ****:   when that's what were to start\n",
      "**** Debug ****:  otherQuestion\n",
      "    -> Generated response:  Ah, you mean like, *start* a conversation! ðŸ˜„  What's on your mind? ðŸ¤” \n",
      "Recording stopped.\n",
      "[+] Recording...\n",
      "**** Debug ****:   When did World War II end?\n",
      "**** Debug ****:  historicalQuestion\n",
      "**** Debug ****: \n",
      "    World War II involved most of the world's nations and was the deadliest conflict in human history.\n",
      "    World War II was fought between two major coalitions: the Allies and the Axis powers.\n",
      "    World War II started on 1 September 1939 with the German invasion of Poland.\n",
      "    World War II set the stage for the Cold War, a decades-long rivalry between the US and USSR.\n",
      "    The war resulted in the division of Germany and the occupation of Berlin by the Allies.\n",
      "**** Debug ****\n",
      "    -> Generated response:  World War II ended on **September 2, 1945**. ðŸ—“ï¸ \n",
      "Recording stopped.\n",
      "[+] Recording...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MPS-Torch/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:483: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Debug ****:   German invade Poland.\n",
      "**** Debug ****:  historicalQuestion\n",
      "**** Debug ****: \n",
      "    World War II started on 1 September 1939 with the German invasion of Poland.\n",
      "    The invasion of Poland led the United Kingdom and France to declare war on Germany on 3 September 1939.\n",
      "    The Soviet Union annexed the Baltic states and parts of Poland after the war.\n",
      "    The war resulted in the division of Germany and the occupation of Berlin by the Allies.\n",
      "    Many new nation-states, such as Poland, Czechoslovakia, and Yugoslavia, were created in Central and Eastern Europe.\n",
      "**** Debug ****\n",
      "    -> Generated response:  The German invasion of Poland happened on **September 1, 1939**. ðŸ‡©ðŸ‡ªðŸ‡µðŸ‡± \n",
      "Recording stopped.\n",
      "[+] Recording...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MPS-Torch/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:483: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Debug ****:   When did United Kingdom declare war on Germany?\n",
      "**** Debug ****:  historicalQuestion\n",
      "**** Debug ****: \n",
      "    The invasion of Poland led the United Kingdom and France to declare war on Germany on 3 September 1939.\n",
      "    The war resulted in the division of Germany and the occupation of Berlin by the Allies.\n",
      "    Winston Churchill became the British Prime Minister in May 1940, leading the UK through much of the war.\n",
      "    Germany surrendered unconditionally on 8 May 1945, celebrated as Victory in Europe (V-E) Day.\n",
      "    The Treaty of Versailles imposed significant territorial and financial penalties on Germany after World War I.\n",
      "**** Debug ****\n",
      "    -> Generated response:  The United Kingdom declared war on Germany on **September 3, 1939**. ðŸ‡¬ðŸ‡§ âš”ï¸ \n",
      "Recording stopped.\n",
      "[+] Recording...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MPS-Torch/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:483: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Debug ****:   Who was the aliens to declare war together?\n",
      "**** Debug ****:  otherQuestion\n",
      "    -> Generated response:  That's a tricky one!  ðŸ‘½  There were no aliens involved in World War II.  It was a conflict between human nations.  ðŸ˜‰ \n",
      "Recording stopped.\n",
      "[+] Recording...\n",
      "**** Debug ****:   Who declared war to Germany together with United Kingdom?\n",
      "**** Debug ****:  otherQuestion\n",
      "    -> Generated response:  France declared war on Germany on September 3, 1939, alongside the United Kingdom. ðŸ‡«ðŸ‡·ðŸ‡¬ðŸ‡§ \n",
      "Recording stopped.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (sound_amp_queue\u001b[38;5;241m.\u001b[39mqsize() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m     13\u001b[0m     sound_amp_queue\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m---> 15\u001b[0m data, overflowed \u001b[38;5;241m=\u001b[39m \u001b[43mvoice_input_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAMPLING_RATE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mREC_DURATION\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m volume_norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(data) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sound_amp_queue\u001b[38;5;241m.\u001b[39mqsize() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/MPS-Torch/lib/python3.12/site-packages/sounddevice.py:1464\u001b[0m, in \u001b[0;36mInputStream.read\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m   1462\u001b[0m dtype, _ \u001b[38;5;241m=\u001b[39m _split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[1;32m   1463\u001b[0m channels, _ \u001b[38;5;241m=\u001b[39m _split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channels)\n\u001b[0;32m-> 1464\u001b[0m data, overflowed \u001b[38;5;241m=\u001b[39m \u001b[43mRawInputStream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1465\u001b[0m data \u001b[38;5;241m=\u001b[39m _array(data, channels, dtype)\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, overflowed\n",
      "File \u001b[0;32m/opt/anaconda3/envs/MPS-Torch/lib/python3.12/site-packages/sounddevice.py:1240\u001b[0m, in \u001b[0;36mRawInputStream.read\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m   1238\u001b[0m samplesize, _ \u001b[38;5;241m=\u001b[39m _split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_samplesize)\n\u001b[1;32m   1239\u001b[0m data \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigned char[]\u001b[39m\u001b[38;5;124m'\u001b[39m, channels \u001b[38;5;241m*\u001b[39m samplesize \u001b[38;5;241m*\u001b[39m frames)\n\u001b[0;32m-> 1240\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPa_ReadStream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m==\u001b[39m _lib\u001b[38;5;241m.\u001b[39mpaInputOverflowed:\n\u001b[1;32m   1242\u001b[0m     overflowed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPS-Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
